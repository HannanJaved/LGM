{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this large version has several differences from the small one.\n",
    "# I tried to annotate all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blabla don't run this on colab\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "os.environ['HTTP_PROXY']='http://proxy:3128/'\n",
    "os.environ['HTTPS_PROXY']='http://proxy:3128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimage\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "\n",
    "from data.utils import parse_image_example\n",
    "from modeling.layers import ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SDLayer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        _, variances = tf.nn.moments(inputs, axes=[0])\n",
    "        global_value = tf.reduce_mean(variances)\n",
    "        broadcast = global_value * tf.ones_like(inputs)\n",
    "        return tf.concat([inputs, broadcast[...,:1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I trained this on multiple GPUs, this is a hold-over from that\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints number of GPUs\n",
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs preprocessed flickr faces data\n",
    "batch_size = 256 * strategy.num_replicas_in_sync\n",
    "train_data = tf.data.TFRecordDataset(\"data/flickr_64_train.TFR\").shuffle(60000).map(parse_image_example).batch(batch_size, drop_remainder=True)\n",
    "test_data = tf.data.TFRecordDataset(\"data/flickr_64_test.TFR\").map(parse_image_example).batch(batch_size)\n",
    "\n",
    "train_data = train_data.map(tf.image.random_flip_left_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.concatenate([batch for batch in iter(test_data)], axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for ind, img in enumerate(test_images[:64]):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as the small one (I think xd)\n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, generator, discriminator, noise_function,\n",
    "                 generator_optimizer, discriminator_optimizer,\n",
    "                 label_smoothing=0.9, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "        \n",
    "        self.noise_function = noise_function\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        self.g_loss_tracker = tf.keras.metrics.Mean(\"generator_loss\")\n",
    "        self.d_loss_tracker = tf.keras.metrics.Mean(\"discriminator_loss\")\n",
    "        self.feature_loss_tracker = tf.keras.metrics.Mean(\"feature_matching_loss\")\n",
    "        \n",
    "    def call(self, noise_input):\n",
    "        # dummy call, needed to be able to load_weights()\n",
    "        return self.discriminator(self.generator(noise_input))\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        data = 2*data - 1\n",
    "        \n",
    "        dequantize_scale = 1/128  # +/- 1 pixel if scaled between -1 and 1\n",
    "        batch_dim = tf.shape(data)[0]\n",
    "\n",
    "        # prepare mixed batch for discriminator training.\n",
    "        # NOTE training=True here is doubtful as we are not actually training the generator here.\n",
    "        # I would recommend avoiding batchnorm, then this question doesn't matter\n",
    "        generated_batch = generator(self.noise_function(batch_dim), training=True)\n",
    "        # one-sided label smoothing applied here\n",
    "        real_labels = self.label_smoothing*tf.ones([batch_dim, 1])\n",
    "        generated_labels = tf.zeros([batch_dim, 1])\n",
    "\n",
    "        # adding noise makes it more difficult and \"de-quantizes\" the data\n",
    "        data = data + tf.random.uniform(tf.shape(data), -dequantize_scale, dequantize_scale)\n",
    "        # tbh I'm not sure if it's necessary to apply it to the generated data s well\n",
    "        generated_batch = generated_batch + tf.random.uniform(tf.shape(generated_batch), -dequantize_scale, dequantize_scale)\n",
    "        \n",
    "        full_batch = tf.concat((data, generated_batch), axis=0)\n",
    "        full_labels = tf.concat((real_labels, generated_labels), axis=0)\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # index [0] into D output since it returns hidden layers as well (for feature matching)\n",
    "            d_loss = self.compiled_loss(full_labels, discriminator(full_batch, training=True)[0])\n",
    "        d_gradients = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        self.discriminator_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
    "\n",
    "        # fresh generated batch for generator training\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as g_tape:\n",
    "            # tape would automatically watch D variables -> wasteful\n",
    "            for variable in generator.trainable_variables:\n",
    "                g_tape.watch(variable)\n",
    "\n",
    "            gen_only_batch = generator(self.noise_function(2*batch_dim), training=True)\n",
    "            gen_only_batch = gen_only_batch + tf.random.uniform(tf.shape(gen_only_batch), -dequantize_scale, dequantize_scale)\n",
    "\n",
    "            d_output_fake = discriminator(gen_only_batch, training=True)\n",
    "            # since we updated D, we need to re-compute the output for the real data for feature matching\n",
    "            d_output_real = discriminator(data, training=True)\n",
    "            # no label smoothing for generator training\n",
    "            g_loss = self.compiled_loss(tf.ones([2*batch_dim, 1]), d_output_fake[0])\n",
    "\n",
    "            feature_match_loss = 0\n",
    "            for fake_feature, real_feature in zip(d_output_fake[1:], d_output_real[1:]):\n",
    "                feature_difference = tf.reduce_mean(fake_feature, axis=0) - tf.reduce_mean(real_feature, axis=0)\n",
    "                feature_match_loss += tf.reduce_sum(feature_difference**2)\n",
    "\n",
    "            g_loss_full = g_loss + feature_match_loss\n",
    "        g_gradients = g_tape.gradient(g_loss_full, generator.trainable_variables)\n",
    "        self.generator_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n",
    "        \n",
    "        self.g_loss_tracker.update_state(g_loss)\n",
    "        self.d_loss_tracker.update_state(d_loss)\n",
    "        self.feature_loss_tracker.update_state(feature_match_loss)\n",
    "\n",
    "        return {\"generator_loss\": self.g_loss_tracker.result(),\n",
    "                \"discriminator_loss\": self.d_loss_tracker.result(),\n",
    "                \"feature_matching_loss\": self.feature_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_tracker, self.d_loss_tracker, self.feature_loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack(inputs, filters, strides, blocks_per_level, mode, name, normalization):\n",
    "    all_outputs = []\n",
    "    outputs = inputs\n",
    "    for level_ind, (level_filters, level_stride) in enumerate(zip(filters, strides)):\n",
    "        for block_ind in range(blocks_per_level):\n",
    "            outputs = ResidualBlock(level_filters,\n",
    "                                    mode, \n",
    "                                    strides=level_stride if block_ind == (blocks_per_level - 1) else 1,\n",
    "                                    name=\"_\".join([name, str(level_ind+1), str(block_ind+1)]),\n",
    "                                    normalization=normalization)(outputs)\n",
    "        all_outputs.append(outputs)\n",
    "        \n",
    "    return all_outputs\n",
    "\n",
    "\n",
    "# this version of the generator \"passes through\" the early noise (here called code)\n",
    "# to all later blocks. this way the blocks have more direct access to the original noise.\n",
    "# maybe this helps =) maybe not\n",
    "def residual_stackD(inputs, code, filters, strides, blocks_per_level, mode, name, normalization):\n",
    "    outputs = inputs\n",
    "    for level_ind, (level_filters, level_stride) in enumerate(zip(filters, strides)):\n",
    "        if level_ind > 0:\n",
    "            code = tfkl.UpSampling2D(interpolation=\"bilinear\")(code)\n",
    "            \n",
    "        for block_ind in range(blocks_per_level):\n",
    "            if level_ind > 0 or block_ind > 0:\n",
    "                combined = tf.concat((outputs, code), axis=-1)\n",
    "            else:\n",
    "                combined = outputs\n",
    "            outputs = ResidualBlock(level_filters,\n",
    "                                    mode, \n",
    "                                    strides=level_stride if block_ind == (blocks_per_level - 1) else 1,\n",
    "                                    name=\"_\".join([name, str(level_ind+1), str(block_ind+1)]),\n",
    "                                    normalization=normalization)(combined)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "normalization = lambda **kwargs: tfkl.GroupNormalization(groups=32, **kwargs)\n",
    "#normalization = tfkl.BatchNormalization\n",
    "\n",
    "# so big wow\n",
    "blocks_per_level = 4\n",
    "filters = [64, 128, 256, 512, 768]\n",
    "strides = [2, 2, 2, 2, 1]\n",
    "\n",
    "with strategy.scope():\n",
    "    discriminator_input = tf.keras.Input((64, 64, 3))\n",
    "    discriminator_outputs = residual_stack(discriminator_input, filters, strides, blocks_per_level, \"conv\", \"discriminator\",\n",
    "                                         normalization)\n",
    "    discriminator_final = tfkl.Flatten()(discriminator_outputs[-1])\n",
    "    discriminator_final = SDLayer()(discriminator_final)\n",
    "    discriminator_final = tfkl.Dense(1)(discriminator_final)\n",
    "\n",
    "    discriminator = tf.keras.Model(discriminator_input, [discriminator_final] + discriminator_outputs, name=\"discriminator\")\n",
    "\n",
    "\n",
    "    # NOTE this time I start with 1D code vector and reshape into the image shape.\n",
    "    # I found this to work a bit better maybe?\n",
    "    # I also start the image already at 8x8 pixels instead of 4x4.\n",
    "    # I really have no clue what is optimal here...\n",
    "    code_shape = (512,)\n",
    "    generator_input = tf.keras.Input(code_shape)\n",
    "    generator_front = tfkl.Dense(8*8*64)(generator_input)\n",
    "    generator_front = tfkl.Reshape((8, 8, 64))(generator_front)\n",
    "    \n",
    "    generator_output = residual_stackD(generator_front, generator_front, reversed(filters[:-1]), strides[1:], blocks_per_level, \"upconv\", \"generator\",\n",
    "                                     normalization)\n",
    "    generator_final = tfkl.Conv2D(3, 1, activation=tf.nn.tanh)(generator_output)\n",
    "\n",
    "    generator = tf.keras.Model(generator_input, generator_final, name=\"generator\")\n",
    "\n",
    "\n",
    "# not happy with the discriminator having 2x as many parameters as the generator.\n",
    "# this may lead to suboptimal performance.\n",
    "discriminator.summary()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_fn(n_samples):\n",
    "    # this is binary noise!\n",
    "    # bernoulli with p=0.5.\n",
    "    return tf.cast(tf.random.uniform((n_samples,) + code_shape, maxval=2, dtype=tf.int32), tf.float32)\n",
    "\n",
    "label_smoothing = 0.9\n",
    "\n",
    "with strategy.scope():\n",
    "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    n_steps = 100000\n",
    "    n_data = 60000\n",
    "    n_epochs = n_steps // (n_data // batch_size)\n",
    "    lr = tf.optimizers.schedules.CosineDecay(0.0002, n_steps)\n",
    "\n",
    "    gen_opt = tf.optimizers.Adam(lr, beta_1=0.5)\n",
    "    disc_opt = tf.optimizers.Adam(lr, beta_1=0.5)\n",
    "\n",
    "    gan = GAN(generator, discriminator, noise_fn, gen_opt, disc_opt)\n",
    "\n",
    "    gan.compile(jit_compile=True, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageGenCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, frequency, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.frequency = frequency\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not epoch % self.frequency:\n",
    "            noise = noise_fn(64)\n",
    "            generated_batch = 0.5 * (self.model.generator(noise) + 1)\n",
    "        \n",
    "            plt.figure(figsize=(15,15))\n",
    "            for ind, image in enumerate(generated_batch):\n",
    "                plt.subplot(8, 8, ind+1)\n",
    "                plt.imshow(image)\n",
    "                plt.axis(\"off\")\n",
    "            plt.suptitle(\"Random generations\")\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    image_gen_callback = ImageGenCallback(5)\n",
    "\n",
    "    history = gan.fit(train_data, epochs=n_epochs, callbacks=[image_gen_callback])\n",
    "    gan.save_weights(\"weights/weights_assignment05_large.hdf5\")\n",
    "\n",
    "else:\n",
    "    # loading weights doesn't work if the model hasn't been called\n",
    "    gan(noise_fn(1))\n",
    "    gan.load_weights(\"weights/weights_assignment05_large.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_codes = noise_fn(64)\n",
    "generated = (generator(random_codes).numpy() + 1) * 0.5\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(generated):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following: \"inference\" for GANs via optimization\n",
    "# this works terribly because we can't optimize binary noise with gradient descent\n",
    "some_imgs = test_images[:32]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(some_imgs):\n",
    "    plt.subplot(8, 4, ind+1)\n",
    "    plt.imshow(image, cmap=\"Greys\", vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def opt_noise(noise, targets):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(noise)\n",
    "        candidate_gen = generator(noise)\n",
    "        gen_error = tf.reduce_mean((candidate_gen - targets)**2)\n",
    "    noise_grad = tape.gradient(gen_error, noise)\n",
    "    noise_opt.apply_gradients(zip([noise_grad], [noise]))\n",
    "    # I at least clip noise to the RANGE [0,1], which is still not binary.\n",
    "    noise.assign(tf.clip_by_value(noise, 0, 1))\n",
    "    \n",
    "    return gen_error\n",
    "\n",
    "    \n",
    "candidate_noise = tf.Variable(noise_fn(32))\n",
    "n_steps = 25001\n",
    "noise_opt = tf.optimizers.Adam(tf.optimizers.schedules.CosineDecay(0.1, n_steps))\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if not step % 2500:\n",
    "        print(step)\n",
    "        current_state = (generator(candidate_noise).numpy() + 1) / 2.\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for ind, image in enumerate(current_state):\n",
    "            plt.subplot(8, 4, ind+1)\n",
    "            plt.imshow(np.concatenate([image, some_imgs[ind]], axis=1), cmap=\"Greys\", vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    gen_error = opt_noise(candidate_noise, 2*some_imgs-1)\n",
    "    \n",
    "    if not step % 2500:\n",
    "        print(\"error\", gen_error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I generated 32 images and set all codes to 0 in one specific dimension. generate images.\n",
    "# then also set all codes to 1 in that same dimension, generate images.\n",
    "# -> the images only differ by one variable flipped.\n",
    "# this could in theory tell us about what that dimension represents.\n",
    "# in practice, results don't tell me anything...\n",
    "random_codes = noise_fn(32)\n",
    "random_codes = np.tile(random_codes, [2, 1])\n",
    "\n",
    "dim = 0\n",
    "if True:\n",
    "    random_codes[:32, dim] = 0\n",
    "    random_codes[32:, dim] = 1\n",
    "\n",
    "#for index in range(4):\n",
    "#    random_codes[8*2*index:8*(2*index+1), index] = 0\n",
    "#    random_codes[8*index:8*(index+1), index + 1] = 1\n",
    "\n",
    "generated = (generator(random_codes).numpy() + 1) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 4 rows: dimn set to 0; rows 5-8: dim set to 1.\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(generated):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
