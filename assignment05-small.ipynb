{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you know... don't run this on colab\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['HTTP_PROXY']='http://proxy:3128/'\n",
    "os.environ['HTTPS_PROXY']='http://proxy:3128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimage\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "\n",
    "from data.utils import parse_image_example\n",
    "from modeling.layers import ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this implements \"Minibatch discrimination\" from the Improved Techniques for Training GANs paper.\n",
    "# I don't use this anymore, but kept it in, whatever\n",
    "class MBD(tf.keras.layers.Layer):\n",
    "    def __init__(self, size_p, size_q):\n",
    "        super(MBD, self).__init__()\n",
    "        self.p = size_p\n",
    "        self.q = size_q\n",
    "        \n",
    "    def build(self, inp_shape):\n",
    "        self.t = self.add_weight(shape=(inp_shape[-1],) + (self.p, self.q),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True)\n",
    "        \n",
    "    def call(self, inp):\n",
    "        #print(inp.shape)  # b x d\n",
    "        # t is d x p x q\n",
    "        # we broadcast features over p and q dims, do pointwise multiplication and sum over the d dim :shrug:\n",
    "        # result is a batch of matrices\n",
    "        weird_mult = tf.reduce_sum(inp[:, :, tf.newaxis, tf.newaxis] * self.t, axis=1)  # b x p x q\n",
    "        #print(weird_mult.shape)\n",
    "        # broadcast to get a b x b x p x q tensor for all (absolute) matrix differences\n",
    "        # then sum over the columns (q) to get differences between rows\n",
    "        # result is b x b x p\n",
    "        weird_diff = tf.exp(-tf.reduce_sum(tf.abs(weird_mult[tf.newaxis] - weird_mult[:, tf.newaxis]), axis=-1))\n",
    "        #print(weird_diff.shape)\n",
    "        # finally sum over all examples to arrive at b x p\n",
    "        return tf.concat([inp, tf.reduce_sum(weird_diff, axis=1)], axis=1)\n",
    "    \n",
    "\n",
    "# this is a much simpler alternative to the abow, from Progressive Growing.\n",
    "# note that the sqrt() may be problematic (gradient is infinite at 0).\n",
    "# it may be better to remove it and work with variances instead.\n",
    "class SDLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SDLayer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        _, variances = tf.nn.moments(inputs, axes=[0])\n",
    "        global_value = tf.reduce_mean(tf.math.sqrt(variances))\n",
    "        broadcast = global_value * tf.ones_like(inputs)\n",
    "        return tf.concat([inputs, broadcast[...,:1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "# MNIST is BOOORING so let's at least use fashion\n",
    "(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images = np.pad(train_images[..., None], ((0, 0), (2, 2), (2, 2), (0, 0))).astype(np.float32) / 255.\n",
    "test_images = np.pad(test_images[..., None], ((0, 0), (2, 2), (2, 2), (0, 0))).astype(np.float32) / 255.\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(batch_size)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.concatenate([batch for batch in iter(test_data)], axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for ind, img in enumerate(test_images[:64]):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(img, vmin=0, vmax=1, cmap=\"Greys\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, generator, discriminator,\n",
    "                 loss_function, noise_function,\n",
    "                 generator_optimizer, discriminator_optimizer,\n",
    "                 label_smoothing=0.9, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "        \n",
    "        self.loss_function = loss_function\n",
    "        self.noise_function = noise_function\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        self.g_loss_tracker = tf.keras.metrics.Mean(\"generator_loss\")\n",
    "        self.d_loss_tracker = tf.keras.metrics.Mean(\"discriminator_loss\")\n",
    "        self.feature_loss_tracker = tf.keras.metrics.Mean(\"feature_matching_loss\")\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        data = 2*data - 1  # scale data to [-1. 1]\n",
    "        \n",
    "        dequantize_scale = 1/128  # +/- 1 pixel if scaled between -1 and 1\n",
    "        batch_dim = tf.shape(data)[0]\n",
    "\n",
    "        # prepare mixed batch for discriminator training.\n",
    "        # NOTE training=True here is doubtful as we are not actually training the generator here.\n",
    "        # I would recommend avoiding batchnorm, then this question doesn't matter\n",
    "        generated_batch = generator(self.noise_function(batch_dim), training=True)\n",
    "        # one-sided label smoothing applied here\n",
    "        real_labels = self.label_smoothing*tf.ones([batch_dim, 1])\n",
    "        generated_labels = tf.zeros([batch_dim, 1])\n",
    "\n",
    "        # adding noise makes it more difficult and \"de-quantizes\" the data\n",
    "        data = data + tf.random.uniform(tf.shape(data), -dequantize_scale, dequantize_scale)\n",
    "        # tbh I'm not sure if it's necessary to apply it to the generated data s well\n",
    "        generated_batch = generated_batch + tf.random.uniform(tf.shape(generated_batch), -dequantize_scale, dequantize_scale)\n",
    "        \n",
    "        full_batch = tf.concat((data, generated_batch), axis=0)\n",
    "        full_labels = tf.concat((real_labels, generated_labels), axis=0)\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # index [0] into D output since it returns hidden layers as well (for feature matching)\n",
    "            d_loss = self.loss_function(full_labels, discriminator(full_batch, training=True)[0]) \n",
    "        d_gradients = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        self.discriminator_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
    "\n",
    "        # fresh generated batch for generator training\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as g_tape:\n",
    "            # tape would automatically watch D variables -> wasteful\n",
    "            for variable in generator.trainable_variables:\n",
    "                g_tape.watch(variable)\n",
    "\n",
    "            gen_only_batch = generator(self.noise_function(2*batch_dim), training=True)\n",
    "            gen_only_batch = gen_only_batch + tf.random.uniform(tf.shape(gen_only_batch), -dequantize_scale, dequantize_scale)\n",
    "\n",
    "            d_output_fake = discriminator(gen_only_batch, training=True)\n",
    "            # since we updated D, we need to re-compute the output for the real data for feature matching\n",
    "            d_output_real = discriminator(data, training=True)\n",
    "            # no label smoothing for generator training\n",
    "            g_loss = loss_fn(tf.ones([2*batch_dim, 1]), d_output_fake[0])\n",
    "\n",
    "            feature_match_loss = 0\n",
    "            for fake_feature, real_feature in zip(d_output_fake[1:], d_output_real[1:]):\n",
    "                feature_difference = tf.reduce_mean(fake_feature, axis=0) - tf.reduce_mean(real_feature, axis=0)\n",
    "                feature_match_loss += tf.reduce_sum(feature_difference**2)\n",
    "\n",
    "            g_loss_full = g_loss + feature_match_loss\n",
    "        g_gradients = g_tape.gradient(g_loss_full, generator.trainable_variables)\n",
    "        self.generator_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n",
    "        \n",
    "        self.g_loss_tracker.update_state(g_loss)\n",
    "        self.d_loss_tracker.update_state(d_loss)\n",
    "        self.feature_loss_tracker.update_state(feature_match_loss)\n",
    "\n",
    "        return {\"generator_loss\": self.g_loss_tracker.result(),\n",
    "                \"discriminator_loss\": self.d_loss_tracker.result(),\n",
    "                \"feature_matching_loss\": self.feature_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_tracker, self.d_loss_tracker, self.feature_loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack(inputs, filters, strides, blocks_per_level, mode, name, normalization):\n",
    "    all_outputs = []\n",
    "    outputs = inputs\n",
    "    for level_ind, (level_filters, level_stride) in enumerate(zip(filters, strides)):\n",
    "        for block_ind in range(blocks_per_level):\n",
    "            outputs = ResidualBlock(level_filters,\n",
    "                                    mode, \n",
    "                                    strides=level_stride if block_ind == (blocks_per_level - 1) else 1,\n",
    "                                    name=\"_\".join([name, str(level_ind+1), str(block_ind+1)]),\n",
    "                                    normalization=normalization)(outputs)\n",
    "        all_outputs.append(outputs)\n",
    "        \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "normalization = lambda **kwargs: tfkl.GroupNormalization(groups=16, **kwargs)\n",
    "#normalization = tfkl.BatchNormalization\n",
    "\n",
    "blocks_per_level = 2\n",
    "filters = [32, 64, 128, 256]\n",
    "strides = [2, 2, 2, 1]\n",
    "\n",
    "\n",
    "discriminator_input = tf.keras.Input((32, 32, 1))\n",
    "discriminator_outputs = residual_stack(discriminator_input, filters, strides, blocks_per_level, \"conv\", \"discriminator\",\n",
    "                                     normalization)\n",
    "discriminator_final = tfkl.Flatten()(discriminator_outputs[-1])\n",
    "discriminator_final = tfkl.Dense(1)(discriminator_final)\n",
    "\n",
    "discriminator = tf.keras.Model(discriminator_input, [discriminator_final] + discriminator_outputs, name=\"discriminator\")\n",
    "\n",
    "\n",
    "# note: the noise is generated directly in \"image shape\" a 4x4 image with 16 channels.\n",
    "# but all \"pixels\" are taken from the noise function.\n",
    "code_shape = (4, 4, 16)\n",
    "generator_input = tf.keras.Input(code_shape)\n",
    "generator_output = residual_stack(generator_input, reversed(filters), strides, blocks_per_level, \"transpose\", \"generator\",\n",
    "                                 normalization)[-1]\n",
    "# tanh output activation to scale to [-1, 1]\n",
    "generator_final = tfkl.Conv2D(1, 1, activation=tf.nn.tanh)(generator_output)\n",
    "\n",
    "generator = tf.keras.Model(generator_input, generator_final, name=\"generator\")\n",
    "\n",
    "\n",
    "discriminator.summary()\n",
    "generator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_fn(n_samples):\n",
    "    return tf.random.normal((n_samples,) + code_shape)\n",
    "    #return tf.random.uniform([n_samples, np.prod(code_shape)], -1., 1.)  # should perform similarly\n",
    "\n",
    "label_smoothing = 0.9\n",
    "\n",
    "loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "n_steps = 50000\n",
    "n_data = 60000\n",
    "n_epochs = n_steps // (n_data // batch_size)\n",
    "lr = tf.optimizers.schedules.CosineDecay(0.001, n_steps)\n",
    "\n",
    "# note the unusual beta, default is 0.9\n",
    "gen_opt = tf.optimizers.Adam(lr, beta_1=0.5)\n",
    "disc_opt = tf.optimizers.Adam(lr, beta_1=0.5)\n",
    "\n",
    "gan = GAN(generator, discriminator, loss_fn, noise_fn, gen_opt, disc_opt)\n",
    "\n",
    "gan.compile(jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageGenCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, frequency, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.frequency = frequency\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not epoch % self.frequency:\n",
    "            noise = noise_fn(64)\n",
    "            generated_batch = 0.5 * (self.model.generator(noise) + 1)\n",
    "        \n",
    "            plt.figure(figsize=(15,15))\n",
    "            for ind, image in enumerate(generated_batch):\n",
    "                plt.subplot(8, 8, ind+1)\n",
    "                plt.imshow(image, vmin=0, vmax=1, cmap=\"Greys\")\n",
    "                plt.axis(\"off\")\n",
    "            plt.suptitle(\"Random generations\")\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    image_gen_callback = ImageGenCallback(10)\n",
    "\n",
    "    history = gan.fit(train_data, epochs=n_epochs, callbacks=[image_gen_callback])\n",
    "    gan.save_weights(\"weights/weights_assignment05_small.hdf5\")\n",
    "\n",
    "else:\n",
    "    gan.load_weights(\"weights/weights_assignment05_small.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_codes = noise_fn(64)\n",
    "generated = (generator(random_codes).numpy() + 1) * 0.5\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(generated):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(image, vmin=0, vmax=1, cmap=\"Greys\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potentially better, but less variable, sampling with truncated noise\n",
    "random_codes = noise_fn(64)\n",
    "lim = 1.  # as you make this smaller, you will get less variety, but possibly better outputs (less noisy, artifact-y)\n",
    "random_codes = tf.clip_by_value(random_codes, -lim, lim)\n",
    "generated = (generator(random_codes).numpy() + 1) * 0.5\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(generated):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(image, vmin=0, vmax=1, cmap=\"Greys\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare FID scores of truncated vs not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following: \"inference\" for GANs via optimization\n",
    "some_imgs = test_images[:32]  # some target images\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, image in enumerate(some_imgs):\n",
    "    plt.subplot(8, 4, ind+1)\n",
    "    plt.imshow(image, cmap=\"Greys\", vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we start with random noise, and optimize the noise such that the generated images become closer to the target ones.\n",
    "# afterwards, we could take the optimized noise and claim those as \"latent variables\" for the generated/target images.\n",
    "# problem: the optimized noise may not be anything like samples from our noise distribution (here, standard normal)!\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def opt_noise(noise, targets):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(noise)\n",
    "        candidate_gen = generator(noise)\n",
    "        gen_error = tf.reduce_mean((candidate_gen - targets)**2)\n",
    "    noise_grad = tape.gradient(gen_error, noise)\n",
    "    noise_opt.apply_gradients(zip([noise_grad], [noise]))\n",
    "    \n",
    "    return gen_error\n",
    "\n",
    "    \n",
    "candidate_noise = tf.Variable(noise_fn(32))\n",
    "noise_opt = tf.optimizers.Adam(0.1)\n",
    "n_steps = 25001\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if not step % 2500:\n",
    "        print(step)\n",
    "        current_state = (generator(candidate_noise).numpy() + 1) / 2.\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for ind, image in enumerate(current_state):\n",
    "            plt.subplot(8, 4, ind+1)\n",
    "            plt.imshow(np.concatenate([image, some_imgs[ind]], axis=1), cmap=\"Greys\", vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    gen_error = opt_noise(candidate_noise, 2*some_imgs-1)\n",
    "    \n",
    "    if not step % 2500:\n",
    "        print(\"error\", gen_error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
